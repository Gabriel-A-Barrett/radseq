include { FASTP as TRIM_FASTP          } from '../../modules/nf-core/fastp/main.nf'
include { PREPARE_FORWARD_READS        } from '../../modules/local/prepare_forward_reads.nf'
include { COMBINE_UNIQUE_READS         } from '../../modules/local/combine_uniq_forward_reads.nf'
include { SEQTK_SEQ                    } from '../../modules/nf-core/seqtk/seq/main.nf'
include { FASTP as DENOVO_FASTP        } from '../../modules/nf-core/fastp/main.nf'
include { CDHIT                        } from '../../modules/nf-core/cdhit/cdhit/main.nf' // cd-hit
include { CDHIT_TO_RBDIV               } from '../../modules/local/cdhit_to_rbdiv.nf'
include { RAINBOW_DIV                  } from '../../modules/local/rainbow/div/rainbow_div.nf' // rainbow div
include { RAINBOW_MERGE                } from '../../modules/local/rainbow/merge/rainbow_merge.nf' // rainbow merge
include { RBMERGE2FASTA as WRITE_FASTA } from '../../modules/local/rbmerge2fasta.nf' // write fasta

    /* Collect individual uniq reads for COMBINING into one Fasta 
    * Combine reads and experiment with thresholds:
    *       WithinIndividualRead_MinimumDepth
    *       BetweenIndividualRead_MinimumDepth
    * uniq sequences -> FASTA format using seqtk seq
    * TRIM reads with large adapter content using fastp
    * Cluster reads using cd-hit est
    */

workflow CDHIT_RAINBOW {
    take:
    reads // [[:], [1.fq.gz, 2.fq.gz]]
    sequence_type // value exe. 'PE' or 'ROP'

    main:
    ch_versions = Channel.empty()

    // perform any necessary trimming 
    def perf_reads = params.need_to_trim_fastq ? TRIM_FASTP(reads, [[],[]], true, false, false).reads : reads

    // deduplicate forward reads
    ch_uniq_forwardreads = PREPARE_FORWARD_READS (perf_reads, sequence_type).indv_uniq_seqs
    ch_versions = ch_versions.mix(PREPARE_FORWARD_READS.out.versions)

    // creates a shared meta.id to condense file paths into
    ch_combine_unique_reads = ch_uniq_forwardreads.map { WorkflowRadseq.groupMetaID(it) }.groupTuple()
 
    def minReadDepth_WithinIndividual = params.minreaddepth_withinindividualList ?: [4,5]
    def minReadDepth_BetweenIndividual = params.minreaddepth_betweenindividualList ?: [4,5]

    // Combine forward reads across individuals
    ch_uniq_full_fasta = COMBINE_UNIQUE_READS (ch_combine_unique_reads.first(), sequence_type, Channel.value(minReadDepth_WithinIndividual), Channel.value(minReadDepth_BetweenIndividual)).uniq_reads
    ch_versions = ch_versions.mix(COMBINE_UNIQUE_READS.out.versions)

    new_ch = ch_uniq_full_fasta.map { WorkflowRadseq.addRefIdToChannels(params, it) }

    // write dummy quality scores for fastp
    ch_uniq_seqtk_fq = SEQTK_SEQ (new_ch).fastx
    ch_versions = ch_versions.mix(SEQTK_SEQ.out.versions)

    // trim adapter content: last true statement activates code block tailored to denovo pipeline since this was based off a nf-core module
    ch_trimadapters_uniq_fasta = DENOVO_FASTP (ch_uniq_seqtk_fq, ch_uniq_full_fasta, false, false, true).fasta
    ch_versions = ch_versions.mix(DENOVO_FASTP.out.versions)

    // cluster
    ch_cdhit_cluster = CDHIT (ch_trimadapters_uniq_fasta, DENOVO_FASTP.out.totaluniqseq, sequence_type).cdhit_cluster
    ch_versions = ch_versions.mix(CDHIT.out.versions)

    // swtich which unique sequence output to fastP vs. CDHIT
    if (params.sequence_type == 'PE' || params.sequence_type == 'SE') {totaluniqseq = DENOVO_FASTP.out.totaluniqseq} else {totaluniqseq = CDHIT.out.forward_uniq}

    // cd-hit cluster to rainbow cluster format
    ch_rbcluster = CDHIT_TO_RBDIV (ch_cdhit_cluster, totaluniqseq, Channel.value(sequence_type)).rbcluster
    ch_versions = ch_versions.mix(CDHIT_TO_RBDIV.out.versions)

    // div
    ch_rbdiv = RAINBOW_DIV (ch_rbcluster).rbdiv
    ch_versions = ch_versions.mix(RAINBOW_DIV.out.versions) // contains awk code not provided in the versions.yml file TODO: awk BusyBox trouble w/ extracting version number within container

    // merge
    ch_rbmerge = RAINBOW_MERGE (ch_rbdiv, sequence_type, true).rbmerge
    ch_versions = ch_versions.mix(RAINBOW_MERGE.out.versions)

    // output fasta
    ch_fasta = WRITE_FASTA (ch_rbdiv, ch_rbmerge, Channel.value(minReadDepth_WithinIndividual), Channel.value(minReadDepth_WithinIndividual)).fasta
    ch_versions = ch_versions.mix(WRITE_FASTA.out.versions)

    emit:
    fasta = ch_fasta
 
    versions = ch_versions
}